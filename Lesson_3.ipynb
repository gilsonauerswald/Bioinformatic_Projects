{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilsonauerswald/Bioinformatic_Projects/blob/main/Lesson_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuM6ruCsRi2P",
        "outputId": "14a37978-8c3a-4dbf-aac8-02894c4729bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Train: 50 samples x 48 genes\n",
            "[Info] Test :  21 samples x 48 genes\n",
            "[Info] Classes: [np.str_('No_Primary_factor'), np.str_('Not_available'), np.str_('alcohol_consumption'), np.str_('hemochromatosis'), np.str_('hepatitis_b'), np.str_('hepatitis_c'), np.str_('non-alcoholic_fatty_liver_disease'), np.str_('other')]\n",
            "[FS] After variance filter: 48 genes\n"
          ]
        }
      ],
      "source": [
        "# rf_pipeline_from_class_row.py\n",
        "# Usage: python rf_pipeline_from_class_row.py\n",
        "# Inputs (TSV, genes in rows, samples in columns): Final_12535train_matrix.txt, Final_12535test_matrix.txt\n",
        "# Each file has a special row named \"class\" giving the label (e.g., StageI/II/III/IV) for every sample.\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import VarianceThresholda\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump\n",
        "\n",
        "# -------------------- Config --------------------\n",
        "TRAIN_PATH = \"https://raw.githubusercontent.com/Omicslogic-git/Project_3_data/refs/heads/main/Final_12535train_matrix.txt\"\n",
        "TEST_PATH  = \"https://raw.githubusercontent.com/Omicslogic-git/Project_3_data/refs/heads/main/Final_12535test_matrix.txt\"\n",
        "OUTDIR = \"rf_outputs\"\n",
        "RANDOM_SEED = 42\n",
        "N_ESTIMATORS = 500\n",
        "VAR_THRESHOLD = 1e-3          # remove near-constant genes\n",
        "TOP_N_IMPORTANCE = 40         # keep top-N genes by importance (after variance filter)\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Load ----------------------\n",
        "train_raw = pd.read_csv(TRAIN_PATH, sep=\"\\t\", index_col=0)\n",
        "test_raw  = pd.read_csv(TEST_PATH,  sep=\"\\t\", index_col=0)\n",
        "\n",
        "# ---- Labels from the `class` row ----\n",
        "assert \"class\" in train_raw.index, \"Row 'class' not found in TRAIN matrix.\"\n",
        "y_train_tokens = train_raw.loc[\"class\"].astype(str).tolist()\n",
        "\n",
        "test_has_labels = \"class\" in test_raw.index\n",
        "y_test_tokens  = (test_raw.loc[\"class\"].astype(str).tolist() if test_has_labels else None)\n",
        "\n",
        "# ---- Drop label row from features ----\n",
        "train_df = train_raw.drop(index=\"class\")\n",
        "test_df  = (test_raw.drop(index=\"class\") if test_has_labels else test_raw)\n",
        "\n",
        "# ---- Align genes between train and test ----\n",
        "common_genes = train_df.index.intersection(test_df.index)\n",
        "train_df = train_df.loc[common_genes]\n",
        "test_df  = test_df.loc[common_genes]\n",
        "\n",
        "# ---- Samples as rows, genes as columns ----\n",
        "X_train = train_df.T.copy()\n",
        "X_test  = test_df.T.copy()\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_tokens)\n",
        "if test_has_labels:\n",
        "    try:\n",
        "        y_test = le.transform(y_test_tokens)\n",
        "    except ValueError:\n",
        "        # If test contains unseen labels, skip accuracy/report computation\n",
        "        test_has_labels = False\n",
        "        y_test = None\n",
        "\n",
        "print(f\"[Info] Train: {X_train.shape[0]} samples x {X_train.shape[1]} genes\")\n",
        "print(f\"[Info] Test :  {X_test.shape[0]} samples x {X_test.shape[1]} genes\")\n",
        "print(f\"[Info] Classes: {list(le.classes_)}\")\n",
        "\n",
        "# ---------------- Feature Selection ----------------\n",
        "# (1) Variance filter\n",
        "vt = VarianceThreshold(threshold=VAR_THRESHOLD)\n",
        "X_train_v = vt.fit_transform(X_train)\n",
        "X_test_v  = vt.transform(X_test)\n",
        "genes_v = X_train.columns[vt.get_support()]\n",
        "print(f\"[FS] After variance filter: {X_train_v.shape[1]} genes\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) Random Forest on variance-filtered features\n",
        "rf_fs = RandomForestClassifier(\n",
        "    n_estimators=N_ESTIMATORS, max_features=\"sqrt\",\n",
        "    class_weight=\"balanced_subsample\", random_state=RANDOM_SEED, n_jobs=-1\n",
        ")\n",
        "rf_fs.fit(X_train_v, y_train)\n",
        "\n",
        "# --- Mean Decrease Gini (built-in) ---\n",
        "gini_importances = pd.Series(rf_fs.feature_importances_, index=genes_v)\n",
        "\n",
        "# --- Mean Decrease Accuracy (permutation importance on training set) ---\n",
        "perm = permutation_importance(\n",
        "    rf_fs, X_train_v, y_train, n_repeats=3, random_state=RANDOM_SEED, n_jobs=-1\n",
        ")\n",
        "\n",
        "# --- Single, combined importance table (one file only) ---\n",
        "fi_combined = pd.DataFrame({\n",
        "    \"Gene\": genes_v,\n",
        "    \"MeanDecreaseGini\": gini_importances.values,\n",
        "    \"MeanDecreaseAccuracy\": perm.importances_mean,\n",
        "    \"MDA_STD\": perm.importances_std\n",
        "}).sort_values(\"MeanDecreaseGini\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Save the one combined file\n",
        "imp_path = os.path.join(OUTDIR, \"feature_importances.csv\")\n",
        "fi_combined.to_csv(imp_path, index=False)\n",
        "\n",
        "# Select top-N genes by Gini (from the combined table)\n",
        "topN = min(TOP_N_IMPORTANCE, fi_combined.shape[0])\n",
        "sel_genes = fi_combined.loc[:topN-1, \"Gene\"]\n",
        "pd.Series(sel_genes, name=\"Gene\").to_csv(os.path.join(OUTDIR, \"selected_genes_topN.txt\"), index=False)\n",
        "\n",
        "# Optional small preview table of the selected topN\n",
        "fi_combined.loc[:topN-1, [\"Gene\", \"MeanDecreaseGini\", \"MeanDecreaseAccuracy\", \"MDA_STD\"]] \\\n",
        "    .to_csv(os.path.join(OUTDIR, \"feature_importances_topN.csv\"), index=False)\n",
        "\n",
        "# Build design matrices with the selected genes\n",
        "X_train_sel = X_train[sel_genes].values\n",
        "X_test_sel  = X_test[sel_genes].values\n",
        "print(f\"[FS] Selected top {topN} genes\")\n",
        "\n",
        "# ---------------- Final RF Model -------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=N_ESTIMATORS, max_features=\"sqrt\",\n",
        "    class_weight=\"balanced_subsample\", random_state=RANDOM_SEED, n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train_sel, y_train)\n",
        "dump(rf, os.path.join(OUTDIR, \"rf_model.joblib\"))\n",
        "\n",
        "# ---------------- Training Results -----------------\n",
        "y_pred_train = rf.predict(X_train_sel)\n",
        "cm = confusion_matrix(y_train, y_pred_train, labels=np.arange(len(le.classes_)))\n",
        "cm_df = pd.DataFrame(cm, index=[f\"True_{c}\" for c in le.classes_],\n",
        "                        columns=[f\"Pred_{c}\" for c in le.classes_])\n",
        "cm_df.to_csv(os.path.join(OUTDIR, \"training_confusion_matrix.csv\"))\n",
        "\n",
        "# Plot (no custom colors)\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(ax=ax, values_format='d', cmap=None)\n",
        "plt.title(\"Random Forest — Training Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTDIR, \"training_confusion_matrix.png\"), dpi=300)\n",
        "plt.close(fig)\n",
        "\n",
        "# Classification report (train)\n",
        "report_train = classification_report(y_train, y_pred_train, target_names=le.classes_, output_dict=True)\n",
        "pd.DataFrame(report_train).T.to_csv(os.path.join(OUTDIR, \"training_classification_report.csv\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWNhskdcRREM",
        "outputId": "177e9764-b510-4934-a81f-b3631571979c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FS] Selected top 40 genes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Test Predictions -----------------\n",
        "y_pred_test = rf.predict(X_test_sel)\n",
        "pred_labels = le.inverse_transform(y_pred_test)\n",
        "test_out = pd.DataFrame({\"Sample\": X_test.index, \"Predicted_Class\": pred_labels})\n",
        "\n",
        "if test_has_labels:\n",
        "    # Save test accuracy and test classification report\n",
        "    test_out[\"True_Class\"] = y_test_tokens\n",
        "    acc = (test_out[\"Predicted_Class\"] == test_out[\"True_Class\"]).mean()\n",
        "    with open(os.path.join(OUTDIR, \"test_accuracy.txt\"), \"w\") as f:\n",
        "        f.write(f\"Test Accuracy: {acc:.4f}\\n\")\n",
        "\n",
        "    report_test = classification_report(y_test, y_pred_test, target_names=le.classes_, output_dict=True)\n",
        "    pd.DataFrame(report_test).T.to_csv(os.path.join(OUTDIR, \"test_classification_report.csv\"))\n",
        "\n",
        "test_out.to_csv(os.path.join(OUTDIR, \"test_predictions.csv\"), index=False)\n",
        "\n",
        "print(\n",
        "    f\"[Done] Wrote outputs to `{OUTDIR}`:\\n\"\n",
        "    \"  - training_confusion_matrix.csv / .png\\n\"\n",
        "    \"  - training_classification_report.csv\\n\"\n",
        "    \"  - test_predictions.csv (+ test_accuracy.txt & test_classification_report.csv if labels present)\\n\"\n",
        "    \"  - feature_importances.csv  (MeanDecreaseGini, MeanDecreaseAccuracy, MDA_STD)\\n\"\n",
        "    \"  - feature_importances_topN.csv\\n\"\n",
        "    \"  - selected_genes_topN.txt\\n\"\n",
        "    \"  - rf_model.joblib\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6d8tWa7RV7a",
        "outputId": "dfa990eb-1903-4ce7-fdd9-b6b0d231a48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Done] Wrote outputs to `rf_outputs`:\n",
            "  - training_confusion_matrix.csv / .png\n",
            "  - training_classification_report.csv\n",
            "  - test_predictions.csv (+ test_accuracy.txt & test_classification_report.csv if labels present)\n",
            "  - feature_importances.csv  (MeanDecreaseGini, MeanDecreaseAccuracy, MDA_STD)\n",
            "  - feature_importances_topN.csv\n",
            "  - selected_genes_topN.txt\n",
            "  - rf_model.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rf_pipeline_improved.py\n",
        "# Usage: python rf_pipeline_improved.py\n",
        "# Adds scaling, ANOVA-based feature selection, and hyperparameter tuning.\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump\n",
        "\n",
        "# -------------------- Config --------------------\n",
        "TRAIN_PATH = \"https://raw.githubusercontent.com/Omicslogic-git/Project_3_data/refs/heads/main/Final_12535train_matrix.txt\"\n",
        "TEST_PATH  = \"https://raw.githubusercontent.com/Omicslogic-git/Project_3_data/refs/heads/main/Final_12535test_matrix.txt\"\n",
        "OUTDIR = \"rf_outputs_improved\"\n",
        "RANDOM_SEED = 42\n",
        "N_ESTIMATORS = 500\n",
        "VAR_THRESHOLD = 1e-3\n",
        "TOP_N_GENES = 200     # increased from 40\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Load ----------------------\n",
        "train_raw = pd.read_csv(TRAIN_PATH, sep=\"\\t\", index_col=0)\n",
        "test_raw  = pd.read_csv(TEST_PATH,  sep=\"\\t\", index_col=0)\n",
        "\n",
        "# ---- Labels ----\n",
        "y_train_tokens = train_raw.loc[\"class\"].astype(str).tolist()\n",
        "test_has_labels = \"class\" in test_raw.index\n",
        "y_test_tokens = (test_raw.loc[\"class\"].astype(str).tolist() if test_has_labels else None)\n",
        "\n",
        "# ---- Drop label row ----\n",
        "train_df = train_raw.drop(index=\"class\")\n",
        "test_df  = (test_raw.drop(index=\"class\") if test_has_labels else test_raw)\n",
        "\n",
        "# ---- Align genes ----\n",
        "common_genes = train_df.index.intersection(test_df.index)\n",
        "train_df = train_df.loc[common_genes]\n",
        "test_df  = test_df.loc[common_genes]\n",
        "\n",
        "X_train = train_df.T.copy()\n",
        "X_test  = test_df.T.copy()\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_tokens)\n",
        "if test_has_labels:\n",
        "    try:\n",
        "        y_test = le.transform(y_test_tokens)\n",
        "    except ValueError:\n",
        "        test_has_labels = False\n",
        "        y_test = None\n",
        "\n",
        "print(f\"[Info] Train: {X_train.shape}, Test: {X_test.shape}, Classes: {list(le.classes_)}\")\n",
        "\n",
        "# ---------------- Feature Selection ----------------\n",
        "# (1) Variance filter\n",
        "vt = VarianceThreshold(threshold=VAR_THRESHOLD)\n",
        "X_train_v = vt.fit_transform(X_train)\n",
        "X_test_v  = vt.transform(X_test)\n",
        "genes_v = X_train.columns[vt.get_support()]\n",
        "\n",
        "print(f\"[FS] After variance filter: {X_train_v.shape[1]} genes\")\n",
        "\n",
        "# (2) ANOVA F-test: keep top-N\n",
        "selector = SelectKBest(score_func=f_classif, k=min(TOP_N_GENES, len(genes_v)))\n",
        "X_train_sel = selector.fit_transform(X_train_v, y_train)\n",
        "X_test_sel  = selector.transform(X_test_v)\n",
        "sel_genes = genes_v[selector.get_support()]\n",
        "pd.Series(sel_genes, name=\"Gene\").to_csv(os.path.join(OUTDIR, \"selected_genes_topN.txt\"), index=False)\n",
        "\n",
        "print(f\"[FS] Selected top {len(sel_genes)} genes by ANOVA F-test\")\n",
        "\n",
        "# ---------------- Scaling ----------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sel)\n",
        "X_test_scaled  = scaler.transform(X_test_sel)\n",
        "\n",
        "# ---------------- Hyperparameter Tuning ----------------\n",
        "param_dist = {\n",
        "    \"n_estimators\": [500, 1000, 1500],\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"class_weight\": [\"balanced\", \"balanced_subsample\"]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "search = RandomizedSearchCV(\n",
        "    rf, param_distributions=param_dist,\n",
        "    n_iter=20, scoring=\"accuracy\", n_jobs=-1,\n",
        "    cv=cv, random_state=RANDOM_SEED, verbose=2\n",
        ")\n",
        "\n",
        "search.fit(X_train_scaled, y_train)\n",
        "rf_best = search.best_estimator_\n",
        "dump(rf_best, os.path.join(OUTDIR, \"rf_model_tuned.joblib\"))\n",
        "\n",
        "print(\"[Tuning] Best Params:\", search.best_params_)\n",
        "print(\"[Tuning] CV Best Score:\", search.best_score_)\n",
        "\n",
        "# ---------------- Training Results -----------------\n",
        "y_pred_train = rf_best.predict(X_train_scaled)\n",
        "cm = confusion_matrix(y_train, y_pred_train, labels=np.arange(len(le.classes_)))\n",
        "pd.DataFrame(cm, index=[f\"True_{c}\" for c in le.classes_],\n",
        "                columns=[f\"Pred_{c}\" for c in le.classes_]) \\\n",
        "  .to_csv(os.path.join(OUTDIR, \"training_confusion_matrix.csv\"))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "disp.plot(ax=ax, values_format='d')\n",
        "plt.title(\"RF (Tuned) — Training Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTDIR, \"training_confusion_matrix.png\"), dpi=300)\n",
        "plt.close(fig)\n",
        "\n",
        "pd.DataFrame(classification_report(\n",
        "    y_train, y_pred_train, target_names=le.classes_, output_dict=True)).T \\\n",
        "  .to_csv(os.path.join(OUTDIR, \"training_classification_report.csv\"))\n",
        "\n",
        "# ---------------- Test Predictions -----------------\n",
        "y_pred_test = rf_best.predict(X_test_scaled)\n",
        "pred_labels = le.inverse_transform(y_pred_test)\n",
        "test_out = pd.DataFrame({\"Sample\": X_test.index, \"Predicted_Class\": pred_labels})\n",
        "\n",
        "if test_has_labels:\n",
        "    test_out[\"True_Class\"] = y_test_tokens\n",
        "    acc = (test_out[\"Predicted_Class\"] == test_out[\"True_Class\"]).mean()\n",
        "    with open(os.path.join(OUTDIR, \"test_accuracy.txt\"), \"w\") as f:\n",
        "        f.write(f\"Test Accuracy: {acc:.4f}\\n\")\n",
        "    pd.DataFrame(classification_report(\n",
        "        y_test, y_pred_test, target_names=le.classes_, output_dict=True)).T \\\n",
        "      .to_csv(os.path.join(OUTDIR, \"test_classification_report.csv\"))\n",
        "\n",
        "test_out.to_csv(os.path.join(OUTDIR, \"test_predictions.csv\"), index=False)\n",
        "\n",
        "print(\"[Done] Improved pipeline finished. Outputs in:\", OUTDIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-PHadjcLrMG",
        "outputId": "009cb57a-f0d6-4dc9-dd6f-e26a83f70848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Train: (50, 12535), Test: (21, 12535), Classes: [np.str_('StageI'), np.str_('StageII'), np.str_('StageIII'), np.str_('StageIV')]\n",
            "[FS] After variance filter: 12535 genes\n",
            "[FS] Selected top 200 genes by ANOVA F-test\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tuning] Best Params: {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None, 'class_weight': 'balanced'}\n",
            "[Tuning] CV Best Score: 0.86\n",
            "[Done] Improved pipeline finished. Outputs in: rf_outputs_improved\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}